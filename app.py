"""
AI æ–‡ç« æª¢æ¸¬å™¨ Streamlit æ‡‰ç”¨ç¨‹å¼
"""

import streamlit as st
import time
import torch
from transformers import RobertaTokenizer, RobertaForSequenceClassification
import numpy as np
from typing import Dict

# ==================== AI æª¢æ¸¬æ¨¡å‹ ====================

class AIDetector:
    def __init__(self):
        """
        åˆå§‹åŒ– AI æª¢æ¸¬å™¨
        ä½¿ç”¨ roberta-base-openai-detector æ¨¡å‹
        """
        self.model_name = "roberta-base-openai-detector"
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        try:
            # è¼‰å…¥é è¨“ç·´æ¨¡å‹å’Œ tokenizer
            self.tokenizer = RobertaTokenizer.from_pretrained(self.model_name)
            self.model = RobertaForSequenceClassification.from_pretrained(self.model_name)
            self.model.to(self.device)
            self.model.eval()
        except:
            # å¦‚æœç„¡æ³•è¼‰å…¥è©²æ¨¡å‹ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ
            print("ç„¡æ³•è¼‰å…¥ roberta-base-openai-detectorï¼Œä½¿ç”¨å‚™ç”¨æ¨¡å‹...")
            self.tokenizer = RobertaTokenizer.from_pretrained("roberta-base")
            self.model = RobertaForSequenceClassification.from_pretrained(
                "roberta-base",
                num_labels=2
            )
            self.model.to(self.device)
            self.model.eval()
    
    def predict(self, text: str) -> Dict[str, float]:
        """
        é æ¸¬æ–‡ç« æ˜¯ç”± AI é‚„æ˜¯äººé¡æ’°å¯«
        
        Args:
            text: è¦æª¢æ¸¬çš„æ–‡ç« å…§å®¹
            
        Returns:
            åŒ…å«é æ¸¬çµæœçš„å­—å…¸ï¼š
            - prediction: "AI" æˆ– "Human"
            - ai_probability: AI æ’°å¯«çš„æ©Ÿç‡ (0-1)
            - human_probability: äººé¡æ’°å¯«çš„æ©Ÿç‡ (0-1)
            - confidence: ä¿¡å¿ƒåˆ†æ•¸ (0-100)
        """
        if not text or len(text.strip()) == 0:
            return {
                "prediction": "Unknown",
                "ai_probability": 0.5,
                "human_probability": 0.5,
                "confidence": 0
            }
        
        # Tokenize è¼¸å…¥æ–‡å­—
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            max_length=512,
            padding=True
        )
        
        # ç§»å‹•åˆ°ç›¸åŒçš„è£ç½®
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # é€²è¡Œé æ¸¬
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=1)
        
        # å–å¾—æ©Ÿç‡å€¼
        probs = probabilities.cpu().numpy()[0]
        
        # å‡è¨­ label 0 = Human, label 1 = AI
        human_prob = float(probs[0])
        ai_prob = float(probs[1])
        
        # åˆ¤æ–·é æ¸¬çµæœ
        prediction = "AI" if ai_prob > human_prob else "Human"
        confidence = max(ai_prob, human_prob) * 100
        
        return {
            "prediction": prediction,
            "ai_probability": ai_prob,
            "human_probability": human_prob,
            "confidence": confidence
        }
    
    def analyze_text_features(self, text: str) -> Dict[str, any]:
        """
        åˆ†ææ–‡å­—ç‰¹å¾µ
        
        Args:
            text: è¦åˆ†æçš„æ–‡å­—
            
        Returns:
            æ–‡å­—ç‰¹å¾µçš„å­—å…¸
        """
        words = text.split()
        sentences = text.split('.')
        
        return {
            "word_count": len(words),
            "sentence_count": len(sentences),
            "avg_word_length": np.mean([len(word) for word in words]) if words else 0,
            "avg_sentence_length": np.mean([len(sent.split()) for sent in sentences if sent.strip()]) if sentences else 0
        }

# ç°¡åŒ–ç‰ˆæœ¬çš„æª¢æ¸¬å™¨ï¼ˆåŸºæ–¼å•Ÿç™¼å¼è¦å‰‡ï¼‰
class SimpleAIDetector:
    """
    ç°¡åŒ–ç‰ˆçš„ AI æª¢æ¸¬å™¨ï¼Œä½¿ç”¨åŸºæœ¬çš„æ–‡å­—ç‰¹å¾µåˆ†æ
    ç•¶ç„¡æ³•è¼‰å…¥æ·±åº¦å­¸ç¿’æ¨¡å‹æ™‚ä½¿ç”¨
    """
    
    def predict(self, text: str) -> Dict[str, float]:
        """
        ä½¿ç”¨ç°¡å–®çš„å•Ÿç™¼å¼è¦å‰‡é æ¸¬
        """
        if not text or len(text.strip()) == 0:
            return {
                "prediction": "Unknown",
                "ai_probability": 0.5,
                "human_probability": 0.5,
                "confidence": 0
            }
        
        # è¨ˆç®—åŸºæœ¬ç‰¹å¾µ
        words = text.split()
        sentences = [s.strip() for s in text.split('.') if s.strip()]
        
        word_count = len(words)
        avg_word_length = np.mean([len(word) for word in words]) if words else 0
        avg_sentence_length = len(words) / len(sentences) if sentences else 0
        
        # ç°¡å–®çš„è©•åˆ†ç³»çµ±
        ai_score = 0
        
        # AI æ–‡ç« é€šå¸¸æœ‰æ›´çµ±ä¸€çš„å¥å­é•·åº¦
        if 15 <= avg_sentence_length <= 25:
            ai_score += 0.2
        
        # AI æ–‡ç« é€šå¸¸ç”¨è©è¼ƒç‚ºæ­£å¼
        if avg_word_length > 5:
            ai_score += 0.15
        
        # AI æ–‡ç« é€šå¸¸çµæ§‹è¼ƒç‚ºå®Œæ•´
        if word_count > 100:
            ai_score += 0.15
        
        # æ¨™æº–åŒ–åˆ†æ•¸
        ai_prob = min(max(ai_score + 0.5, 0), 1)
        human_prob = 1 - ai_prob
        
        prediction = "AI" if ai_prob > 0.5 else "Human"
        confidence = abs(ai_prob - 0.5) * 200  # è½‰æ›ç‚º 0-100
        
        return {
            "prediction": prediction,
            "ai_probability": ai_prob,
            "human_probability": human_prob,
            "confidence": confidence
        }
    
    def analyze_text_features(self, text: str) -> Dict[str, any]:
        """åˆ†ææ–‡å­—ç‰¹å¾µ"""
        words = text.split()
        sentences = text.split('.')
        
        return {
            "word_count": len(words),
            "sentence_count": len(sentences),
            "avg_word_length": np.mean([len(word) for word in words]) if words else 0,
            "avg_sentence_length": np.mean([len(sent.split()) for sent in sentences if sent.strip()]) if sentences else 0
        }

# ==================== Streamlit æ‡‰ç”¨ç¨‹å¼ ====================

# é é¢è¨­å®š
st.set_page_config(
    page_title="AI æ–‡ç« æª¢æ¸¬å™¨",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾© CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .result-box {
        padding: 2rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .ai-result {
        background-color: #ffebee;
        border-left: 5px solid #f44336;
    }
    .human-result {
        background-color: #e8f5e9;
        border-left: 5px solid #4caf50;
    }
    .metric-card {
        background-color: #f5f5f5;
        padding: 1rem;
        border-radius: 5px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ– session state
if 'detector' not in st.session_state:
    st.session_state.detector = None
    st.session_state.model_loaded = False

@st.cache_resource
def load_model():
    """è¼‰å…¥ AI æª¢æ¸¬æ¨¡å‹"""
    try:
        detector = AIDetector()
        return detector, True
    except Exception as e:
        st.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Œä½¿ç”¨ç°¡åŒ–ç‰ˆæª¢æ¸¬å™¨ã€‚éŒ¯èª¤: {str(e)}")
        detector = SimpleAIDetector()
        return detector, False

# ä¸»æ¨™é¡Œ
st.markdown('<div class="main-header">ğŸ¤– AI æ–‡ç« æª¢æ¸¬å™¨</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">æª¢æ¸¬æ–‡ç« æ˜¯ç”± AI é‚„æ˜¯äººé¡æ’°å¯«</div>', unsafe_allow_html=True)

# å´é‚Šæ¬„
with st.sidebar:
    st.header("â„¹ï¸ é—œæ–¼")
    st.info("""
    é€™å€‹å·¥å…·ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ä¾†åˆ†ææ–‡ç« å…§å®¹ï¼Œ
    åˆ¤æ–·æ–‡ç« æ˜¯ç”± AI é‚„æ˜¯äººé¡æ’°å¯«ã€‚
    
    **ä½¿ç”¨æ–¹æ³•ï¼š**
    1. åœ¨æ–‡å­—æ¡†ä¸­è¼¸å…¥æˆ–è²¼ä¸Šæ–‡ç« 
    2. é»æ“Šã€Œé–‹å§‹æª¢æ¸¬ã€æŒ‰éˆ•
    3. æŸ¥çœ‹æª¢æ¸¬çµæœ
    """)
    
    st.header("ğŸ“Š æ¨¡å‹è³‡è¨Š")
    if st.button("è¼‰å…¥æ¨¡å‹"):
        with st.spinner("æ­£åœ¨è¼‰å…¥æ¨¡å‹..."):
            st.session_state.detector, st.session_state.model_loaded = load_model()
        if st.session_state.model_loaded:
            st.success("âœ… æ·±åº¦å­¸ç¿’æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
        else:
            st.info("â„¹ï¸ ä½¿ç”¨ç°¡åŒ–ç‰ˆæª¢æ¸¬å™¨")
    
    if st.session_state.detector is not None:
        st.success("âœ… æ¨¡å‹å·²å°±ç·’")
    else:
        st.warning("âš ï¸ è«‹å…ˆè¼‰å…¥æ¨¡å‹")
    
    st.header("ğŸ“ ç¯„ä¾‹æ–‡ç« ")
    if st.button("è¼‰å…¥ AI æ–‡ç« ç¯„ä¾‹"):
        st.session_state.example_text = """Artificial intelligence has revolutionized numerous industries in recent years. Machine learning algorithms can now process vast amounts of data with unprecedented efficiency. These technological advancements have enabled computers to perform tasks that were once exclusively human domains. From natural language processing to image recognition, AI systems continue to demonstrate remarkable capabilities. The integration of deep learning techniques has particularly enhanced the performance of these systems."""
    
    if st.button("è¼‰å…¥äººé¡æ–‡ç« ç¯„ä¾‹"):
        st.session_state.example_text = """I remember the first time I tried to write an essay. It was tough! My thoughts were all over the place, and I couldn't figure out how to organize them. But you know what? That's totally normal. Writing is messy. Sometimes I'd write a sentence, hate it, delete it, then write it again almost the same way. That's just how it goes, right?"""

# ä¸»è¦å…§å®¹å€åŸŸ
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ“ è¼¸å…¥æ–‡ç« ")
    
    # æ–‡å­—è¼¸å…¥å€
    default_text = st.session_state.get('example_text', '')
    text_input = st.text_area(
        "è«‹è¼¸å…¥æˆ–è²¼ä¸Šè¦æª¢æ¸¬çš„æ–‡ç« å…§å®¹ï¼š",
        value=default_text,
        height=300,
        placeholder="åœ¨é€™è£¡è¼¸å…¥æ–‡ç« å…§å®¹...",
        key="text_input"
    )
    
    # æ–‡å­—çµ±è¨ˆ
    if text_input:
        word_count = len(text_input.split())
        char_count = len(text_input)
        st.caption(f"ğŸ“Š å­—æ•¸çµ±è¨ˆï¼š{word_count} å€‹è© | {char_count} å€‹å­—å…ƒ")
    
    # æª¢æ¸¬æŒ‰éˆ•
    detect_button = st.button("ğŸ” é–‹å§‹æª¢æ¸¬", type="primary", use_container_width=True)

with col2:
    st.header("âš™ï¸ è¨­å®š")
    
    show_details = st.checkbox("é¡¯ç¤ºè©³ç´°åˆ†æ", value=True)
    show_probabilities = st.checkbox("é¡¯ç¤ºæ©Ÿç‡åœ–è¡¨", value=True)

# è™•ç†æª¢æ¸¬
if detect_button:
    if st.session_state.detector is None:
        st.error("âŒ è«‹å…ˆåœ¨å´é‚Šæ¬„è¼‰å…¥æ¨¡å‹ï¼")
    elif not text_input or len(text_input.strip()) < 10:
        st.warning("âš ï¸ è«‹è¼¸å…¥è‡³å°‘ 10 å€‹å­—å…ƒçš„æ–‡ç« å…§å®¹")
    else:
        # é¡¯ç¤ºé€²åº¦
        with st.spinner("ğŸ” æ­£åœ¨åˆ†ææ–‡ç« ..."):
            progress_bar = st.progress(0)
            for i in range(100):
                time.sleep(0.01)
                progress_bar.progress(i + 1)
            
            # é€²è¡Œé æ¸¬
            result = st.session_state.detector.predict(text_input)
        
        st.success("âœ… åˆ†æå®Œæˆï¼")
        
        # é¡¯ç¤ºçµæœ
        st.header("ğŸ“Š æª¢æ¸¬çµæœ")
        
        # ä¸»è¦çµæœ
        result_class = "ai-result" if result['prediction'] == "AI" else "human-result"
        result_icon = "ğŸ¤–" if result['prediction'] == "AI" else "ğŸ‘¤"
        
        st.markdown(f"""
        <div class="result-box {result_class}">
            <h2 style="margin:0;">{result_icon} æª¢æ¸¬çµæœï¼š{result['prediction']}</h2>
            <h3 style="margin-top:1rem;">ä¿¡å¿ƒåˆ†æ•¸ï¼š{result['confidence']:.2f}%</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # æ©Ÿç‡åœ–è¡¨
        if show_probabilities:
            st.subheader("ğŸ“ˆ æ©Ÿç‡åˆ†ä½ˆ")
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    label="ğŸ¤– AI æ’°å¯«æ©Ÿç‡",
                    value=f"{result['ai_probability']*100:.2f}%"
                )
                st.progress(result['ai_probability'])
            
            with col2:
                st.metric(
                    label="ğŸ‘¤ äººé¡æ’°å¯«æ©Ÿç‡",
                    value=f"{result['human_probability']*100:.2f}%"
                )
                st.progress(result['human_probability'])
        
        # è©³ç´°åˆ†æ
        if show_details and hasattr(st.session_state.detector, 'analyze_text_features'):
            st.subheader("ğŸ“ æ–‡å­—ç‰¹å¾µåˆ†æ")
            features = st.session_state.detector.analyze_text_features(text_input)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f"""
                <div class="metric-card">
                    <h4>å­—æ•¸</h4>
                    <h2>{features['word_count']}</h2>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="metric-card">
                    <h4>å¥å­æ•¸</h4>
                    <h2>{features['sentence_count']}</h2>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"""
                <div class="metric-card">
                    <h4>å¹³å‡è©é•·</h4>
                    <h2>{features['avg_word_length']:.1f}</h2>
                </div>
                """, unsafe_allow_html=True)
            
            with col4:
                st.markdown(f"""
                <div class="metric-card">
                    <h4>å¹³å‡å¥é•·</h4>
                    <h2>{features['avg_sentence_length']:.1f}</h2>
                </div>
                """, unsafe_allow_html=True)
        
        # è§£é‡‹èªªæ˜
        with st.expander("â“ å¦‚ä½•è§£è®€çµæœ"):
            st.markdown("""
            - **ä¿¡å¿ƒåˆ†æ•¸**ï¼šè¡¨ç¤ºæ¨¡å‹å°é æ¸¬çµæœçš„ä¿¡å¿ƒç¨‹åº¦ï¼ˆ0-100%ï¼‰
            - **æ©Ÿç‡åˆ†ä½ˆ**ï¼šé¡¯ç¤ºæ–‡ç« å±¬æ–¼ AI æˆ–äººé¡æ’°å¯«çš„æ©Ÿç‡
            - **æ–‡å­—ç‰¹å¾µ**ï¼šåˆ†ææ–‡ç« çš„åŸºæœ¬çµ±è¨ˆè³‡è¨Š
            
            **æ³¨æ„äº‹é …ï¼š**
            - æ­¤å·¥å…·åƒ…ä¾›åƒè€ƒï¼Œä¸ä¿è­‰ 100% æº–ç¢º
            - è¼ƒçŸ­çš„æ–‡ç« å¯èƒ½å½±éŸ¿æª¢æ¸¬æº–ç¢ºåº¦
            - å»ºè­°çµåˆå¤šç¨®æ–¹æ³•é€²è¡Œåˆ¤æ–·
            """)

# é å°¾
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666;">
    <p>ğŸ“ 5114056002_HW5 | Built with Streamlit & Transformers</p>
</div>
""", unsafe_allow_html=True)
